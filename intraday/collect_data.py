import requests
import pandas as pd
import os
import time
from datetime import datetime, timedelta

# --- CONFIGURATION ---
TIINGO_API_KEYS = [
    "",
    "",
    ""
]

CURRENT_KEY_INDEX = 0
CONSECUTIVE_429 = 0

DATA_FOLDER = "data_1min"

# Tes actions
TICKERS = [
    "NVDA", "AMD", "TSLA", "COIN", "SHOP", "PLTR", "SNOW", "NET", "U",
    "RIVN", "LCID", "PLUG", "ENPH", "MRNA", "CRSP", "TDOC", "AMC", "GME", "SPCE",
    "MARA", "MSTR"
]

# L'objectif : Jusqu'o√π veut-on remonter dans le pass√© ? (ex: 2021-01-01)
GOAL_DATE = datetime(2021, 1, 1)

# --- FONCTIONS ---

def get_current_start_date(ticker):
    """Lit le CSV et retourne la date la plus ancienne enregistr√©e."""
    file_path = os.path.join(DATA_FOLDER, f"{ticker}_1min.csv")
    
    if not os.path.exists(file_path):
        # Si pas de fichier, on consid√®re que l'historique commence "Maintenant"
        return datetime.now()
    
    try:
        # On lit le CSV
        df = pd.read_csv(file_path)
        if df.empty:
            return datetime.now()
        
        # On r√©cup√®re la premi√®re date
        first_date = pd.to_datetime(df['date'].iloc[0])
        
        # --- LE FIX EST ICI ---
        # Si la date a une timezone (UTC), on la retire pour pouvoir comparer
        if first_date.tzinfo is not None:
            first_date = first_date.tz_localize(None)
            
        return first_date

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lecture {ticker}: {e}")
        return datetime.now()

        
def merge_and_save(ticker, new_df):
    """Fusionne les nouvelles donn√©es (anciennes dates) avec l'existant."""
    file_path = os.path.join(DATA_FOLDER, f"{ticker}_1min.csv")
    
    if os.path.exists(file_path):
        old_df = pd.read_csv(file_path, index_col=0)
        # Conversion index en datetime pour √™tre s√ªr
        old_df.index = pd.to_datetime(old_df.index)
        
        # On concat√®ne : [Vieux_Data_Recuper√©] + [Data_Deja_La]
        full_df = pd.concat([new_df, old_df])
        
        # On nettoie les doublons (au cas o√π les dates se chevauchent)
        full_df = full_df[~full_df.index.duplicated(keep='last')]
        full_df.sort_index(inplace=True)
    else:
        full_df = new_df

    full_df.to_csv(file_path)
    return full_df.index.min(), len(full_df)

def download_previous_month(ticker, current_start_date):
    """T√©l√©charge le mois pr√©c√©dent la date donn√©e."""

    global CURRENT_KEY_INDEX, CONSECUTIVE_429

    end_date = current_start_date
    start_date = end_date - timedelta(days=30)
    
    # Formattage API
    fmt = '%Y-%m-%d'
    url = f"https://api.tiingo.com/iex/{ticker}/prices?startDate={start_date.strftime(fmt)}&endDate={end_date.strftime(fmt)}&resampleFreq=1min&columns=date,open,high,low,close,volume"
    
    current_key = TIINGO_API_KEYS[CURRENT_KEY_INDEX]

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Token {current_key}'
    }
    
    try:
        print(f"‚¨áÔ∏è  {ticker}({CURRENT_KEY_INDEX +1}) : T√©l√©chargement {start_date.strftime(fmt)} -> {end_date.strftime(fmt)} ... ", end="")
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            CONSECUTIVE_429 = 0
            data = response.json()
            if data:
                df = pd.DataFrame(data)
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
                print(f"‚úÖ {len(df)} lignes.")
                return df
            else:
                print("‚ö†Ô∏è  Vide (Pas de data √† cette p√©riode).")
                return pd.DataFrame() # Vide mais pas None
        elif response.status_code == 429:
            print(f"\nüõë Limite atteinte sur la cl√© n¬∞{CURRENT_KEY_INDEX +1}.")

            CONSECUTIVE_429 += 1
            if CONSECUTIVE_429 >= len(TIINGO_API_KEYS):
                print("‚ùó Toutes les cl√©s ont atteint la limite. Pause de 1 minute.")
                CONSECUTIVE_429 = 0
                time.sleep(60)
            
            CURRENT_KEY_INDEX = (CURRENT_KEY_INDEX + 1) % len(TIINGO_API_KEYS)
            print(f"üîÄ On passe √† la cl√© {CURRENT_KEY_INDEX + 1} pour le prochain essai.")

            return None # On renvoie None pour dire "r√©essaie"
        else:
            print(f"‚ùå Erreur {response.status_code}")
            return pd.DataFrame()
            
    except Exception as e:
        print(f"‚ùå Exception: {e}")
        return pd.DataFrame()

# --- MAIN LOOP ---

if __name__ == "__main__":
    if not os.path.exists(DATA_FOLDER):
        os.makedirs(DATA_FOLDER)

    print(f"üèóÔ∏è  Lancement de l'Arch√©ologue. Objectif : Remonter jusqu'√† {GOAL_DATE.date()}")

    while True:
        # 1. ANALYSE DE L'ETAT ACTUEL
        # On cr√©e une liste de (Ticker, Date_Debut_Actuelle)
        status_list = []
        finished_count = 0
        
        print("\nüîç Analyse des fichiers...")
        for ticker in TICKERS:
            start_date = get_current_start_date(ticker)
            if start_date <= GOAL_DATE:
                finished_count += 1
            else:
                status_list.append((ticker, start_date))
        
        # Condition de sortie : Si tout le monde a atteint la date cible
        if finished_count == len(TICKERS):
            print("\nüéâ MISSION ACCOMPLIE ! Tous les fichiers remontent jusqu'√† l'objectif.")
            break
            
        # 2. CHOIX DE LA CIBLE (Celui qui est le plus "en retard" dans le pass√©)
        # On trie pour avoir la date la plus RECENTE en premier (donc celui qui a le moins d'historique)
        status_list.sort(key=lambda x: x[1], reverse=True)
        
        target_ticker, target_date = status_list[0]
        
        print(f"üéØ Priorit√© : {target_ticker} (Historique commence le {target_date.date()})")
        print(f"   Reste √† t√©l√©charger : {(target_date - GOAL_DATE).days} jours d'historique.")
        
        # 3. ACTION
        new_data = download_previous_month(target_ticker, target_date)
        
        if new_data is None:
            # Cas du Rate Limit (429), on boucle pour retenter sans changer de cible
            continue
            
        if not new_data.empty:
            new_min, total_lines = merge_and_save(target_ticker, new_data)
            print(f"   üíæ Sauvegard√©. Nouveau d√©but : {new_min} (Total lignes: {total_lines})")
        else:
            # Si c'est vide (ex: week-end ou jour f√©ri√© ou action n'existait pas encore),
            # on force artificiellement la date de recul pour ne pas boucler √† l'infini sur la m√™me p√©riode vide.
            # On cr√©e un CSV vide ou on met √† jour pour dire "j'ai v√©rifi√© cette p√©riode".
            # Astuce simple : on ne fait rien ici, car le merge_and_save ne sera pas appel√©, 
            # MAIS il faut avancer sinon on boucle. 
            # Pour ce script simple : Si vide, on consid√®re qu'on a "trait√©" la zone en cr√©ant un dummy record 
            # ou en acceptant que pour cette action, on ne trouvera rien avant.
            
            # Solution robuste : Si vide, on d√©cale quand m√™me la target date de 30 jours en arri√®re dans le fichier ?
            # C'est complexe sans modifier le fichier.
            # Solution pragmatique : On affiche "Vide" et on fait une pause,
            # Mais pour √©viter la boucle infinie si l'action n'existait pas en 2021 (ex: RIVN),
            # Il faut d√©tecter si on est AVANT l'IPO.
            
            if target_ticker == "RIVN" and target_date.year < 2021:
                 # Hack sp√©cifique ou logique g√©n√©rale : si vide 3 fois de suite, on consid√®re fini ?
                 # Pour l'instant, on recule la "date de scan" virtuellement
                 pass
            
            # Pour √©viter de bloquer, si on re√ßoit vide, on va tricher :
            # On va ins√©rer une ligne vide avec la date n-30 pour forcer le syst√®me √† croire qu'on a des donn√©es
            # C'est sale mais √ßa d√©bloque la boucle.
            dummy_df = pd.DataFrame({'open': [0]}, index=[target_date - timedelta(days=30)])
            dummy_df.index.name = 'date'
            merge_and_save(target_ticker, dummy_df)
            print("   ‚ö†Ô∏è P√©riode vide d√©tect√©e, on marque le terrain et on recule.")

        # 4. TEMPO
        time.sleep(2) # Respect de l'API